{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NICD Centre for Vaccines and Immunology: Wastewater Genomics","text":"<p>The National Institute for Communicable Diseases\u2019 Centre for Vaccines and Immunology (CVI) in South Africa conducts surveillance of various pathogens, including SARS-Cov-2, measles, rubella, hepatitis A, hepatitis E, polio, influenza A, and influenza B, using wastewater-based epidemiology and genomic techniques. Additionally, clinical data is gathered from patients in selected reference hospitals as part of this comprehensive surveillance initiative. The information generated through this surveillance program serves as a valuable resource, offering regular updates on the trends and impact associated with the monitored pathogens. These updates are made accessible to the public, the broader medical community, healthcare practitioners, and policymakers. This documentation page is intended to serve as a reference guide, outlining the procedures for conducting analyses  routinely performed in our reporting and publications.</p> <p>For more information, please visit the NICD website</p> <p>For more information on SARS-CoV-2 wastewater-based genomic epidemiology please click here</p>"},{"location":"influenza/","title":"How to analyse influenza A and B from wastewater samples","text":"<p>The graphs are produced using R version 4.2.2 or higher and the following packages are required to run the script:</p> <p>These following libraries are required to run this script: </p> <pre><code>library(ggplot2)\nlibrary(ggthemes)\nlibrary(scales)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(rlang)\nlibrary(writexl)\nlibrary(scales)\nlibrary(EpiCurve)\nlibrary(ISOweek)\nlibrary(writexl)\nlibrary(tidyr)\nlibrary(reshape2)\n</code></pre>"},{"location":"influenza/#preparing-the-data","title":"Preparing the data","text":"<p>Wastewater surveillance data is stored on RedCap. Export the data as a csv and set a path to your folders where you have stored the latest wastewater data download. Read in the data using the read.csv() function</p> <pre><code>setwd(\"C:/set/path/to/folder\")\n\nInfluenza &lt;- read.csv(\"C:/path/to/file/Wastewatergeneral_DATA_LABELS_2024-07-11_0948.csv\")\n</code></pre> <p>Select the following variables from the wastewater data that you have read into R</p> <pre><code>Influenza &lt;- Influenza[, c(\"Site.Province.\",  \"District.Name\",\n                       \"Site.Name.\", \"Sample.Collection.Date\", \"Inf.A.Result\", \"Inf.B.Result.\")]\n</code></pre> <p>Create an EpiWeek variables that uses the samples collection date to determine the epidemiological week</p> <pre><code>Influenza_2 &lt;- mutate(Influenza, EpiWeek = ISOweek(Sample.Collection.Date))\n</code></pre> <p>Making sure all blank spaces are now replaced with NAs </p> <pre><code>Influenza_3 &lt;- Influenza_2 %&gt;%\n    mutate_all(~ ifelse(. == \"\", NA, .))\n</code></pre> <p>Filter the data for Influenza A results only </p> <pre><code>Influenza_4 &lt;- Influenza_3 %&gt;%\n  filter(!is.na(Inf.A.Result))\n</code></pre> <p>Group Influenza A results by epidemiological week (tabulates the number of positive and negative influenza A results for each week)</p> <pre><code>InfluenzaA &lt;- Influenza_4 %&gt;%\n  group_by(EpiWeek) %&gt;%\n  summarize(\n    Positive_WW = sum(Inf.A.Result == 'Positive'),\n    Negative_WW = sum(Inf.A.Result == 'Negative'),\n    Total = n())\n</code></pre> <p>Add column with the percentage positivity rates</p> <pre><code>InfluenzaA$positivityrate &lt;- (InfluenzaA$Positive_WW / InfluenzaA$Total)*100\n</code></pre> <p>Remove rows where there is no epidemiological week recorded (NAs)</p> <pre><code>InfluenzaA_final &lt;- InfluenzaA %&gt;%\n  filter(!is.na(EpiWeek))\n</code></pre> <p>Filter for only 2024</p> <pre><code>InfluenzaA_final_24 &lt;- filter(InfluenzaA_final, EpiWeek &gt;= \"2024-W01\")\n</code></pre> <p>Filter the data for Influenza B results only</p> <pre><code>Influenza_5 &lt;- Influenza_3 %&gt;%\n  filter(!is.na(Inf.B.Result.))\n</code></pre> <p>Group Influenza B results by epidemiological week (tabulates the number of positive and negative influenza B results for each week)</p> <pre><code>InfluenzaB &lt;- Influenza_5 %&gt;%\n  group_by(EpiWeek) %&gt;%\n  summarize(\n    Positive_WW = sum(Inf.B.Result. == 'Positive'),\n    Negative_WW = sum(Inf.B.Result. == 'Negative'),\n    Total = n())\n</code></pre> <p>Add column with the percentage positivity rates</p> <pre><code>InfluenzaB$positivityrate &lt;- (InfluenzaB$Positive_WW / InfluenzaB$Total)*100\n</code></pre> <p>Remove rows where there is no epidemiological week recorded (NAs)</p> <pre><code>InfluenzaB_final &lt;- InfluenzaB %&gt;%\n  filter(!is.na(EpiWeek))\n</code></pre> <p>Filter for only 2024</p> <pre><code>InfluenzaB_final_24 &lt;- filter(InfluenzaB_final, EpiWeek &gt;= \"2024-W01\")\n</code></pre>"},{"location":"influenza/#producing-plots-with-percentage-positivity-and-absolute-number-of-positive-samples-by-epidemiological-week","title":"Producing plots with percentage positivity and absolute number of positive samples by epidemiological week","text":"<p>Produce the plot for Influenza A (limits of axis and the number used to divide the positivity rate may need adjusting depending on the maximum number of absolute positives in any given epidemiological week)</p> <pre><code>InfluenzaA_plot &lt;- ggplot(InfluenzaA_final_24, aes(x = EpiWeek)) +\n  geom_bar(aes(y = Positive_WW, fill = \"Positive Wastewater Samples\"), \n       stat = \"identity\", colour = \"plum\") +\n  geom_point(aes(y = positivityrate / 4, color = \"Positivity Rate\"), size = 2) +\n  geom_line(aes(y = positivityrate / 4, color = \"Positivity Rate\", group = 1)) +\n  labs(x = \"EpiWeek\", \n   y = \"Number of Positive Wastewater Samples\", \n   title = \"Influenza A\",\n   fill = \"Legend\",  # Custom label for the fill legend\n   color = \"Legend\") + # Custom label for the color legend\n  scale_y_continuous(name = \"Number of Positive Wastewater Samples\", \n                 limits = c(0, 25),\n                 sec.axis = sec_axis(~ . /25, \n                                     name = \"Percentage Positive\", \n                                     labels = scales::percent)) +\n  scale_color_manual(name = \"Line (Secondary y-axis)\", values = c(\"Positivity Rate\" = \"black\")) +\n  scale_fill_manual(name = \"Bars (Primary y-axis)\", values = c(\"Positive Wastewater Samples\" = \"plum\")) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12),  \n    axis.text.y = element_text(size = 14),  # Adjusting y-axis text size\n    axis.title = element_text(size = 14),   # Adjusting axis title size\n    legend.text = element_text(size = 14),  \n    legend.title = element_text(size = 14))\n</code></pre> <p>Set the desired width and height for the PNG </p> <pre><code>width = 15\nheight = 8\n</code></pre> <p>Save as a PNG</p> <pre><code>ggsave(\"InfluenzaA_200717.png\", InfluenzaA_plot, width = width, height = height)\n</code></pre> <p>Produce the plot for Influenza B (limits of axis and the number used to divide the positivity rate may need adjusting depending on the maximum number of absolute positives in any given epidemiological week</p> <pre><code>InfluenzaB_plot &lt;- ggplot(InfluenzaB_final_24, aes(x = EpiWeek)) +\n  geom_bar(aes(y = Positive_WW, fill = \"Positive Wastewater Samples\"), \n       stat = \"identity\", colour = \"lightblue\") +\n  geom_point(aes(y = positivityrate / 5.88, color = \"Positivity Rate\"), size = 2) +\n  geom_line(aes(y = positivityrate / 5.88, color = \"Positivity Rate\", group = 1)) +\n  labs(x = \"EpiWeek\", \n   y = \"Number of Positive Wastewater Samples\", \n   title = \"InfluenzaB\",\n   fill = \"Legend\",  # Custom label for the fill legend\n   color = \"Legend\") + # Custom label for the color legend\n  scale_y_continuous(name = \"Number of Positive Wastewater Samples\", \n                 limits = c(0, 17),\n                 breaks = seq(0, 17, by = 2),  # Set breaks to only whole numbers\n                 sec.axis = sec_axis(~ . /17, \n                                     name = \"Percentage Positive\", \n                                     labels = scales::percent)) +\n  scale_color_manual(name = \"Line (Secondary y-axis)\", values = c(\"Positivity Rate\" = \"black\")) +\n  scale_fill_manual(name = \"Bars (Primary y-axis)\", values = c(\"Positive Wastewater Samples\" = \"lightblue\")) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 12),  \n    axis.text.y = element_text(size = 14),  # Adjusting y-axis text size\n    axis.title = element_text(size = 14),   # Adjusting axis title size\n    legend.text = element_text(size = 14),  \n    legend.title = element_text(size = 14))\n</code></pre> <p>Set the desired width and height for the PNG </p> <pre><code>width = 15\nheight = 8\n</code></pre> <p>Save as a PNG</p> <pre><code>ggsave(\"InfluenzaB_200717.png\", InfluenzaB_plot, width = width, height = height)\n</code></pre>"},{"location":"labtat/","title":"Turnaround Times","text":""},{"location":"labtat/#laboratory-and-sequencing-turnaround-times","title":"Laboratory And Sequencing Turnaround Times","text":"<p>Timely reporting of sample test results is required to support the wastewater-based  surveillance of pathogens. This ensure that any changes in the transmission of pathogens circulating  within the population or even circulating variants may be detected in a timely manner. </p> <p>Laboratory turnaround times (tat) are plotted each week to help rapidly identify delays at various  points at which samples are processed. This helps us quickly identify what may be causing delays and  address any challenges which may be faced. </p> <p>There are two graphs generated: one for the time taken to produce the quantitative levels of SARS-CoV-2 in wastewater,  and the other for the time taken to produce the sequencing results for those samples. The graphs produced illustrate the number of samples collected and processed during each week as a bar graph, and a line graph representing the average turnaround  time of all samples during a given week. </p>"},{"location":"labtat/#setting-up","title":"Setting up","text":"<p>The graphs are produced using R version 4.2.2 or higher and the following packages are required to run the script: </p> <pre><code>library(ggthemes)\nlibrary(scales)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(lubridate)\n</code></pre> <p>RedCap is used by our team as a database to capture and store sample information. There are two ways in which data may be exported for use . The first is to download a csv file from RedCap. The read.csv() function will be used to import the the csv file into a dataframe. The types of data within each column may be specified using col_types. The coloumns don't always have to specied,but sometimes dates may be imported as numeric values. So specifying the columns helps prevent that from happening. </p> <pre><code>water &lt;- read.csv(\"Path/to/the/file.csv\", check.names = F) #Replace the path with the path to the file on your computer\n</code></pre> <p>Alternatively, the RedCap API token may be used to automatically connect to RedCap within the R script, such that fresh data is taken from RedCap without the need to manually export the data.  To obtain the API token, log into RedCap and select API on the left hand side under the Applications tab. Generate an API token and insert into the code below (Ensure you have permissions from your administrator). The RedCap API  playground may also be used if you would like to modify the code below to suit your specific requirements.</p> <pre><code>token &lt;- \"insert-api-toke-here\"\nurl &lt;- \"insert-redcap-url-here\"\nformData &lt;- list(\"token\"=token,\n             content='record',\n             action='export',\n             format='csv',\n             type='flat',\n             csvDelimiter='',\n             rawOrLabel='raw',\n             rawOrLabelHeaders='raw',\n             exportCheckboxLabel='false',\n             exportSurveyFields='false',\n             exportDataAccessGroups='false',\n             returnFormat='json'\n)\nresponse &lt;- httr::POST(url, body = formData, encode = \"form\")\nresult &lt;- httr::content(response)\n\nwater &lt;- result\n</code></pre> <p>Before getting started, we're going to ensure that all date columns are being read in by R as a date. This step is not really necessary, but good to have. </p> <pre><code>water$sam_col_date &lt;- as.Date(water$sam_col_date)\nwater$proc_date &lt;- as.Date(water$proc_date)\nwater$pcr_test_date &lt;- as.Date(water$pcr_test_date)\nwater$extraction_date &lt;- as.Date(water$extraction_date )\nwater$pcr_date &lt;- as.Date(water$pcr_date)\nwater$tapestation_date &lt;- as.Date(water$tapestation_date )\nwater$date_rec_sequences &lt;- as.Date(water$date_rec_sequences)\nwater$date_sub_sequencing &lt;- as.Date(water$date_sub_sequencing)\nwater$seq_report_date &lt;- as.Date(water$seq_report_date)\n</code></pre>"},{"location":"labtat/#calculating-the-epidemiological-weeks-epiweeks","title":"Calculating the epidemiological weeks (epiweeks)","text":"<p>We now need to add in a column containing the epiweeks. To ensure that no errors occur in our original \"water\" dataframe while we perform some data wrangling, we'll create a second dataframe, which we'll call \"water1\"</p> <pre><code>water1&lt;- water\n</code></pre> <p>The strftime() function can be used to create a year and month column based on when the sample was collected </p> <pre><code>water1$year &lt;- strftime(water1$`Date sample collected`, \"%Y\") #Creating year column  \nwater1$month &lt;- strftime(water1$`Date sample collected`, \"%m\") #Creating month column\n</code></pre> <p>The epiweek may also be calculated using the lubridate to calculate the epiweek based on the date that the sample was collected. Lubricate requires that the date format be specified and since our dates are recorded as yyyy-mm-dd we'll specify that the formwat is ymd</p> <pre><code>water1$epiweek &lt;- lubridate::epiweek(ymd(water1$`Date sample collected`))\n</code></pre> <p>For most our reports we report the epiweeks with the year combined (e.g. 2023w45) We can create a column containing the combined year and epiweek. We start by creating a column with the week represented as a \"w\" </p> <pre><code>water1$week &lt;- \"w\" #added column with w\n</code></pre> <p>Week can then combine what's in the \"year\", \"week\" and \"epiweek\" column and then send it to a new variable called \"epiweek2\"</p> <pre><code>my_cols2 &lt;- c(\"year\", \"week\", \"epiweek\") #new data object with 3 columns combined\nwater1$epiweek2 &lt;- do.call(paste, c(water1[my_cols2],sep =\"\")) #created new variable using concat columns\n</code></pre> <p>To ensure that all data is ordered by the year the sample was collected, and then by epidemiological week </p> <pre><code>water &lt;-  water[ #ordering by year first then week\nwith(water, order(year, week)),\n]\n</code></pre>"},{"location":"labtat/#calculating-turnaround-times-for-quantitative-results","title":"Calculating turnaround times for quantitative results","text":"<p>Because we only started recording the tat around the end of April 2023, we have to filter out all other samples collected before this period </p> <pre><code>watertat &lt;- water1 %&gt;% \nfilter(sam_col_date &gt; \"2023-04-30\")\n</code></pre> <p>The tat for each sample may then be calculated by calculating the difference in time by various processes conducted in the lab. The difference is calculated in days</p> <pre><code>watertat$pro_tat &lt;- difftime(watertat$`Date Processed`,watertat$`Date sample collected`, units = c(\"days\"))\nwatertat$lab_tat &lt;- difftime(watertat$`Date tested at Laboratory`,watertat$`Date Processed`, units = c(\"days\"))\nwatertat$overall_tat &lt;- difftime(watertat$`Date tested at Laboratory`,watertat$`Date sample collected`, units = c(\"days\"))\n</code></pre> <p>To calculate the mean tat for all samples given a specific epiweek </p> <pre><code>mean_pro &lt;- watertat%&gt;% # we specify which df we would like to use\ngroup_by(epiweek2)%&gt;% # we specify what we would like to group by \nsummarise(Meanpro=mean(pro_tat, na.rm = TRUE))\n\nmean_lab &lt;- watertat%&gt;% # we specify which df we would like to use\ngroup_by(epiweek2)%&gt;% # we specify what we would like to group by \nsummarise(Meanlab=mean(lab_tat, na.rm = TRUE))\n\nmean_overall &lt;- watertat%&gt;% # we specify which df we would like to use\ngroup_by(epiweek2)%&gt;% # we specify what we would like to group by \nsummarise(Meanoverall=mean(overall_tat, na.rm = TRUE))\n</code></pre> <p>Since we've calculated the tat, we need to created a new dataframe with the  mean tat and the number of samples collected during a given epiweek. To tabulate the number of samples collected during each epiweek we can do </p> <pre><code>freq_samples &lt;- watertat %&gt;%\ngroup_by(epiweek2)%&gt;%\ncount(epiweek2, na.rm=TRUE)\n</code></pre> <p>We then need create a new dataframe which contains the number of samples collected during each week and  how long it took to process those samples</p> <pre><code>tat_vs_freq &lt;- merge(mean_pro, mean_lab, by= \"epiweek2\", na.rm =TRUE)\ntat_vs_freq &lt;- merge(tat_vs_freq, mean_overall, by= \"epiweek2\", na.rm =TRUE)\ntat_vs_freq &lt;- merge(tat_vs_freq, freq_samples, by= \"epiweek2\", na.rm =TRUE)\n</code></pre> <p>Since we've captured our epiweeks in the year-w-week format (eg. 2023w45), when plotting this on the x-axis, R will plot the epiweeks in lexicographic order instead of by year first and then by week. In order to force R to plot the epiweeks in the correct order, we will first creat a new column called epiweek 3. Epiweek 3 will be  a duplication of epiweek 2. We will then separate the year and week and  order the dataframe by year and then week.</p> <pre><code>tat_vs_freq$epiweek3 &lt;- tat_vs_freq$epiweek2\n\ntat_vs_freq &lt;- tat_vs_freq %&gt;% \n    separate(epiweek3,into=c(\"year\", \"week\"), \n     sep=\"w\", convert = TRUE, extra = \"merge\")\n\ntat_vs_freq &lt;-  tat_vs_freq[ #ordering by year first then week\nwith(tat_vs_freq, order(year, week)),\n]\n</code></pre> <p>Since we will be plotting from epiweek2, we now tell R to treat epiweek2 as a factor, and that if there are multiple entries for a given epiweek it must only take one unique epiweek. Lastly, that it must keep the same order as the dataframe</p> <pre><code>tat_vs_freq$epiweek2 &lt;- factor(tat_vs_freq$epiweek2, levels = unique(tat_vs_freq$epiweek2), ordered = T)\n</code></pre> <p>Now that we have a dataframe (tat_vs_freq) that contains how many samples were collected during each epiweek and how long it took to process those samples,  we can plot that on a graph. </p> <p>To specify that the graph should be saved as a .png file, we can use the png() function and specify the path of the folder for which the file should be saved in. The dimensions of the graph may also be specified to your desired width and height. </p> <pre><code>png(\"path/to/file/quantitative.png\", \nwidth = 5*900,\nheight = 5*500,\nres = 300,\npointsize = 8)\n</code></pre> <p>To plot the graph, ggplot2 will be used. We first specify which dataframe will be used to build the graph:</p> <pre><code>tat_plot &lt;- ggplot(tat_vs_freq) +\n</code></pre> <p>To specify that we want to create a bar dark gray bar graph with epiweeks on the x-azis and number of samples collected (n) on the y-axis</p> <pre><code>geom_bar(aes(x=epiweek2, y=n),stat=\"identity\", fill=\"darkgray\",\n         colour=\"darkgray\")+\n</code></pre> <p>To create three line graphs on top on the bar graph which show the average time it takes for samples to be processed (meanpro), samples to be quantified in the lab (meanlab) as well as the overall time (meanoverall). The mean turnaround times will be  displayed on a secondary y-axis. Because the number of days is generally less than the number of samples collected, it affects  the scale between the two y-axes. We can then multiply the values of the y-axis by 10 to ensure that they will be visible when plotting.</p> <pre><code>geom_line(aes(x=epiweek2, y=Meanpro*10, colour= \"Meanpro\", group=1),stat=\"identity\", size=1.5)+\ngeom_line(aes(x=epiweek2, y=Meanlab*10, colour= \"Meanlab\", group=1),stat=\"identity\", size=1.5)+\ngeom_line(aes(x=epiweek2, y=Meanoverall*10, colour= \"Meanoverall\", group=1),stat=\"identity\", size=1.5)+\n</code></pre> <p>To manually change the colours and labels of each line graph produced we can used the scale_colour_manual() function</p> <pre><code>scale_colour_manual(labels = c(\"Sample Preparation\", \"Quantification\", \"Overall\"), \n                  breaks = c(\"Meanpro\", \"Meanlab\",\"Meanoverall\" ),\n                  values = c(\"forestgreen\", \"black\", \"skyblue\")) +\n\n\nscale_y_continuous(sec.axis=sec_axis(~ . /10,name=\"Mean TAT in days\\n\")) + \nlabs(x=\"Epiweek\",y=\"Number of samples collected\\n\")+\nggthemes::theme_hc()+\ntheme(\naxis.ticks.x= element_blank(), \naxis.text.x = element_text(angle = 90, hjust = 0, size = 20),\naxis.text.y = element_text(size = 20),\nlegend.position=\"bottom\",\nlegend.title = element_blank(),\ntext = element_text( size=20),\naxis.line.x = element_line(color=\"black\", size = 1),\naxis.line.y = element_line(color=\"black\", size = 1)) +\ngeom_text(aes(label = n, x=epiweek2, y=n), vjust = -0.5, colour = \"black\", size = 6)\n\ntat_plot\n\ndev.off()\n</code></pre> <p></p>"},{"location":"labtat/#calculating-turnaround-times-for-sequencing-results","title":"Calculating turnaround times for sequencing results","text":"<p>Since only PCR-positive samples are submitted for sequencing, we first filter out samples that were not sent for sequencing</p> <pre><code>water &lt;- water %&gt;% \nfilter(!is.na(water$date_sub_sequencing))\n</code></pre> <p>We then calculate TAT for each sample similar to what was done above </p> <pre><code>seq_water$extraction_tat &lt;- difftime(seq_water$`Extraction Date`, \n                                 seq_water$`Date tested at Laboratory`\n                                 , units = c(\"days\"))\n\nseq_water$pcr_tat &lt;- difftime(seq_water$`PCR Date`, \n                          seq_water$`Extraction Date`, \n                          units = c(\"days\"))\n\nseq_water$tapestation_tat &lt;- difftime(seq_water$`Tapestation Date`, \n                                  seq_water$`PCR Date`, \n                                  units = c(\"days\"))\n\nseq_water$sequencing_tat &lt;- difftime(seq_water$`Date received from Sequencing`,\n                                 seq_water$`Date submitted for Sequencing`, \n                                 units = c(\"days\"))\n\nseq_water$seq_report_tat &lt;- difftime(seq_water$`Report Date`,\n                                 seq_water$`Date received from Sequencing`, \n                                 units = c(\"days\"))\n\nseq_water$overall &lt;- difftime(seq_water$`Report Date` ,seq_water$`Date tested at Laboratory`, units = c(\"days\"))\n</code></pre> <p>This is then used to calculate the mean TAT for each epiweek</p> <pre><code>mean_extraction_tat &lt;- seq_water%&gt;% # we specify which df we would like to use\ngroup_by(epiweek2)%&gt;% # we specify what we would like to group by \nsummarise(Extraction=mean(extraction_tat, na.rm = TRUE))\n\nmean_pcr_tat &lt;- seq_water%&gt;% # we specify which df we would like to use\ngroup_by(epiweek2)%&gt;% # we specify what we would like to group by \nsummarise(PCR=mean(pcr_tat, na.rm = TRUE))\n\nmean_tapestation_tat &lt;- seq_water%&gt;% # we specify which df we would like to use\ngroup_by(epiweek2)%&gt;% # we specify what we would like to group by \nsummarise(Tapestation=mean(tapestation_tat, na.rm = TRUE))\n\nmean_sequencing_tat &lt;- seq_water%&gt;% # we specify which df we would like to use\ngroup_by(epiweek2)%&gt;% # we specify what we would like to group by \nsummarise(Sequencing=mean(sequencing_tat, na.rm = TRUE))\n\nmean_seq_report_tat &lt;- seq_water%&gt;% # we specify which df we would like to use\ngroup_by(epiweek2)%&gt;% # we specify what we would like to group by \nsummarise(`Sequencing Report`=mean(seq_report_tat, na.rm = TRUE))\n\nmean_overall &lt;- seq_water%&gt;% # we specify which df we would like to use\ngroup_by(epiweek2)%&gt;% # we specify what we would like to group by \nsummarise(Overall=mean(overall, na.rm = TRUE))\n</code></pre> <p>We then tabulate the number of samples received by epiweek </p> <pre><code>freq_samples2 &lt;- seq_water %&gt;%\ngroup_by(epiweek2)%&gt;%\ncount(epiweek2, na.rm=TRUE)\n</code></pre> <p>A new dataframe is then created with the mean TAT and number of samples received. Since the merge function only takes two dataframes at time, we merge two dataframes at a time</p> <pre><code>seqtat_vs_freq &lt;- merge(mean_extraction_tat, mean_pcr_tat, by=\"epiweek2\", na.rm =TRUE)\nseqtat_vs_freq &lt;- merge(seqtat_vs_freq, mean_tapestation_tat, by=\"epiweek2\", na.rm =TRUE)\nseqtat_vs_freq &lt;- merge(seqtat_vs_freq, mean_sequencing_tat, by=\"epiweek2\", na.rm =TRUE)\nseqtat_vs_freq &lt;- merge(seqtat_vs_freq, mean_seq_report_tat, by=\"epiweek2\", na.rm =TRUE)\nseqtat_vs_freq &lt;- merge(seqtat_vs_freq, mean_overall, by=\"epiweek2\", na.rm =TRUE)\nseqtat_vs_freq &lt;- merge(seqtat_vs_freq, freq_samples2, by=\"epiweek2\", na.rm =TRUE)\n</code></pre> <p>A plot may now be created showing the TAT for each laboratory process</p> <pre><code>png(\"/path/to/file/sequencing.png\", \n    width = 5*900,\n    height = 5*500, \n    res = 300,\n    pointsize = 8)\n\ntat_plot2 &lt;- ggplot(seqtat_vs_freq) +\ngeom_bar(aes(x=epiweek2, y=n),stat=\"identity\", fill=\"darkgray\",\n       colour=\"darkgray\")+\ngeom_line(aes(x=epiweek2, y=Extraction, colour= \"Extraction\", group=1),stat=\"identity\", size=1.5) +\ngeom_line(aes(x=epiweek2, y=PCR, colour= \"PCR\", group=1),stat=\"identity\", size=1.5) +\ngeom_line(aes(x=epiweek2, y=Tapestation, colour= \"Tapestation\", group=1),stat=\"identity\", size=1.5) +\ngeom_line(aes(x=epiweek2, y=Sequencing, colour= \"Sequencing\", group=1),stat=\"identity\", size=1.5)+\ngeom_line(aes(x=epiweek2, y=`Sequencing Report`, colour= \"Sequencing Report\", group=1),stat=\"identity\", size=1.5)+\ngeom_line(aes(x=epiweek2, y=Overall, colour= \"Overall\", group=1),stat=\"identity\", size=1.5)+\nscale_y_continuous(sec.axis=sec_axis(~ . ,name=\"Mean TAT in days\\n\"))+ \nlabs(x=\"Epiweek\",y=\"Number of samples collected\\n\")+\nggthemes::theme_hc()+\ntheme(\n    axis.ticks.x= element_blank(), \n    axis.text.x = element_text(angle = 90, hjust = 0, size = 20),\n    axis.text.y = element_text(size = 20),\n    legend.position=\"bottom\",\n    legend.title = element_blank(),\n    text = element_text( size=20),\n    axis.line.x = element_line(color=\"black\", size = 1),\n    axis.line.y = element_line(color=\"black\", size = 1)) +\ngeom_text(aes(label = n, x=epiweek2, y=n), vjust = -0.5, colour = \"black\", size = 6)\n\ntat_plot2\n\ndev.off()\n</code></pre> <p></p>"},{"location":"quantitative/","title":"SARS-CoV-2 Quantitative Levels","text":""},{"location":"quantitative/#sars-cov-2-quantitative-levels-analysis","title":"SARS-CoV-2 Quantitative Levels Analysis","text":"<p>The National Institute for Communicable Diseases (NICD) currently oversees SARS-CoV-2 surveillance through two key methods:  tracking changes in reported clinical cases documented in the NICD's Notifiable Medical Conditions Reporting's(NMC) register,  and observing variations in SARS-CoV-2 levels detected by performing a PCR test on wastewater samples.  These dual metrics, clinical data and wastewater analysis, can be conveniently visualized together in a unified graph.  This guide offers detailed instructions on performing such analysis and visualization.</p> <p>The graphs are produced using R version 4.2.2 or higher and the following packages are required to run the script:</p> <pre><code>library (ggplot2)\nlibrary(ggthemes)\nlibrary(scales)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(lubridate)\nlibrary(rlang)\nlibrary(writexl)\n</code></pre>"},{"location":"quantitative/#preparing-clinical-case-data","title":"Preparing clinical case data","text":"<p>Access to clinical data is restricted, and permissions must be obtained from the NMC. Once Access is obtained, clinical case data is downloaded from the NMC linelist. The data is exported as excel files.  Due to the large volume of cases in some years, there may be multiple excel files produced, as excel has a limit in the number of rows that per file. The first step would be import all the files into R dataframes: </p> <pre><code>cov211&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_1.xlsx\")\ncov212&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_2.xlsx\")\ncov213&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_3.xlsx\")\ncov214&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_4.xlsx\")\ncov215&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_5.xlsx\")\ncov216&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_6.xlsx\")\ncov217&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_7.xlsx\")\ncov218&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_8.xlsx\")\ncov219&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_9.xlsx\")\ncov2110&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_10.xlsx\")\ncov2111&lt;- read_xlsx(\"/path/to/file/SARS//covid_21_11.xlsx\")\ncov221&lt;- read_xlsx(\"/path/to/file/SARS//covid_22_1.xlsx\")\ncov222&lt;- read_xlsx(\"/path/to/file/SARS//covid_22_2.xlsx\")\ncov223&lt;- read_xlsx(\"/path/to/file/SARS/covid_22_3.xlsx\")\ncov23&lt;- read_xlsx(\"/path/to/file/SARS/covid_23.xlsx\")\ncov24&lt;- read_xlsx(\"/path/to/file/SARS/covid_24.xlsx\")\n</code></pre> <p>Now that we have multiple dataframes created, we want to create one dataframe to work with. To do this we are going to  bind each of the dataframes into one \"covcases\" dataframe using the bind_rows command. Bind rows allows you to merge dataframe that have  the same column names in such a way that all the rows in one dataframe are added below the rows of another. </p> <pre><code>covcases &lt;- bind_rows(cov211, cov212, cov213, cov214, cov215, cov216, cov217, cov218, cov219, \n                  cov2110, cov2111, cov221, cov222,cov223, cov23, cov24)\n</code></pre> <p>At this point, you may want to have a look at the clinical cases in the dataframe (df) in which case you can view them using:      View(cases)</p> <p>If you're unsure of all the disctricts included in the df, you can create a table to count all the unique districts </p> <pre><code>table(covcases$District)\n</code></pre> <p>As there are many districts across the country, we only want to filter for districts in which we collect wastewater samples. To do this we'll use the filter command from the tidyverse library. </p> <pre><code>covcases &lt;- covcases %&gt;%\nfilter(District == \"GP CITY OF JOHANNESBURG METRO\" | District == \"City of Johannesburg Metro\" |\n       District == \"FS MANGAUNG METRO\" | District == \"Mangaung Metro\" |\n       District == \"EC NELSON MANDELA BAY METRO\" | District == \"eThekwini Metro\" |\n       District == \"GP CITY OF TSHWANE METRO\" | District == \"City of Tshwane Metro\" |\n       District == \"GP EKURHULENI METRO\" | District == \"Ekurhuleni Metro\" |\n       District == \"KZN ETHEKWINI METRO\" | District == \"eThekwini Metro\" |\n       District == \"WC CITY OF CAPE TOWN METRO\" | District == \"City of Cape Town Metro\" |\n       District == \"EC BUFFALO CITY METRO\"| District == \"Buffalo City Metro\" |\n       District == \"NW BOJANALA PLATINUM\"| District == \"Bojanala Platinum\" |\n       District == \"NW DR KENNETH KAUNDA\"| District ==  \"Dr Kenneth Kaunda\" )\n</code></pre> <p>For most surveillance reports produced by the NICD, results are reported according to epidemiological weeks (epiweeks).  For this report we will also be using epiweeks to report our findings. In order to convert the sample collection dates to epiweeks,  we'll use the lubridate library to create a new column with the epiweeks of laboratory confirmed SARS-CoV-2 cases: </p> <pre><code>covcases &lt;- covcases %&gt;% \nfilter(Diagnosis_Method == \"Laboratory confirmed\")\ncovcases$newcoldate &lt;- format(as.Date(covcases$Notification_Date, format = \"%Y/%m/%d\"), \"%Y-%m-%d\") #changing the format of the date from y/m/d to ymd \ncovcases$epiweek &lt;- lubridate::epiweek(ymd( covcases$newcoldate)) #generate epiweek\n</code></pre> <p>In the epiweek column you will find a number representing the epiweek the sample was collected in. For example, if a sample was collected on 2024-04-25, then the number would be \"17\". However, we like to report our epiweeks with the year combined (eg 2024w17). This is just a matter of preference,  and may be modified to suit your preferences. In order to add the year onto the epiweek with a \"w\" inbetween, we first create a column with the year the sample was created, and then another column with \"w\" and concatenate the year, \"w\" and epiweek column to get our desired format:</p> <pre><code>covcases$year &lt;- strftime(covcases$newcoldate, \"%Y\") #Creating year column  \ncovcases$week &lt;- \"w\" #added column with w\nmy_cols &lt;- c(\"year\", \"week\", \"epiweek\") #new data object with 3 columns combined\ncovcases$epiweek2 &lt;- do.call(paste, c(covcases[my_cols],sep =\"\")) #created new variable using concat columns\n\ncases1 &lt;- covcases\n</code></pre> <p>Since we report findings nationally and at a district level, we want to also create dataframes for each district. We'll do this by filtering for only the  clinical cases found in that district. As R is case-sensitive, we'll filter for all variations in spelling of the districts found in the linelist. </p> <pre><code>joburg_cases &lt;- cases1 %&gt;%\nfilter(District == \"GP CITY OF JOHANNESBURG METRO\" | District == \"City of Johannesburg Metro\")\n\nmangaung_cases &lt;- cases1 %&gt;%\nfilter(District == \"FS MANGAUNG METRO\" | District == \"Mangaung Metro\")\n\nnelson_cases &lt;- cases1 %&gt;%\nfilter(District == \"EC NELSON MANDELA BAY METRO\" | District == \"eThekwini Metro\" )\n\ntshwane_cases &lt;- cases1 %&gt;%\nfilter( District == \"GP CITY OF TSHWANE METRO\" | District == \"City of Tshwane Metro\")\n\nekurhuleni_cases &lt;- cases1 %&gt;%\nfilter(District == \"GP EKURHULENI METRO\" | District == \"Ekurhuleni Metro\" )\n\nethekwini_cases &lt;- cases1 %&gt;%\nfilter(District == \"KZN ETHEKWINI METRO\" | District == \"eThekwini Metro\")\n\ncapetown_cases &lt;- cases1 %&gt;%\nfilter(District == \"WC CITY OF CAPE TOWN METRO\" | District == \"City of Cape Town Metro\" )\n\nbuffalo_cases &lt;- cases1 %&gt;%\nfilter(District == \"EC BUFFALO CITY METRO\"| District == \"Buffalo City Metro\" )\n\nbojanala_cases &lt;- cases1 %&gt;%\nfilter(District == \"NW BOJANALA PLATINUM\"| District == \"Bojanala Platinum\" )\n\njb_marks_cases &lt;- cases1 %&gt;%\nfilter(District == \"NW DR KENNETH KAUNDA\"| District ==  \"Dr Kenneth Kaunda\" )\n</code></pre>"},{"location":"quantitative/#preparing-wastewater-levels","title":"Preparing wastewater levels","text":"<p>There are two ways in which you can import the wastewater data in this R script. The first is by importing a csv file</p> <pre><code>water &lt;- read.csv(\"path/to.file.csv\")\n</code></pre> <p>Or using an API token from RedCap, which is the data management system used by our team. We usually use the API token as it allows us to  automatically run this script without having to first download directly from RedCap. </p> <pre><code>token &lt;- \"insert your private token here\"\nurl &lt;- \"insert RedCap URL here\"\nformData &lt;- list(\"token\"=token,\n             content='record',\n             action='export',\n             format='csv',\n             type='flat',\n             csvDelimiter='',\n             rawOrLabel='label',\n             rawOrLabelHeaders='raw',\n             exportCheckboxLabel='false',\n             exportSurveyFields='false',\n             exportDataAccessGroups='false',\n             returnFormat='json'\n)\nresponse &lt;- httr::POST(url, body = formData, encode = \"form\")\nresult &lt;- httr::content(response)\n\nwater &lt;- result\n</code></pre> <p>We then filter for the wastewater treatment plants (WWTP) that we would like to include in the report: </p> <pre><code>water &lt;- water %&gt;% \n  filter( site_name == \"Northern Wastewater Treatment Works (GP)\" |\n        site_name == \"Northern Wastewater Treatment Works (KZN)\"| \n        site_name == \"Rooiwal Wastewater Treatment Works\"| \n        site_name ==  \"ERWAT Vlakplaat Wastewater Treatment Works\"|\n        site_name ==  \"Central Wastewater Treatment Works (KZN)\"|\n        site_name ==  \"Goudkoppies Wastewater Treatment Works\"|\n        site_name ==  \"Hartebeesfontein Waterworks\"|\n        site_name ==  \"Daspoort Wastewater Treatment Works\" |\n        site_name ==  \"Zandvleit Wastewater Treatment Works\"|\n        site_name == \"Borcheds Quarry Wastewater Treatment Works\"|\n        site_name == \"Brickfield Pre-treatment Works\" |\n        site_name == \"Sterkwater Wastewater Treatment Works\"|\n        site_name == \"Bloemspruit Wastewater Treatment Works\"|\n        site_name ==  \"Kwanobuhle Wastewater Treatment Works\" |\n        site_name == \"East Bank Wastewater Treatment Works\"| \n        site_name ==  \"Mdantsane Wastewater Treatment Works\" |\n        site_name == \"Mmabatho Water Treatment Works\" |\n        site_name == \"Musina WWTW (in town)\" |\n        site_name == \"Kingstonvale\"|\n        site_name == \"Boitekong\"| \n        site_name == \"Rustenburg Wastewater Treatment Works\" |\n        site_name == \"Nancefield\"| \n        site_name == \"Komatipoort Sewage plant\"|\n        site_name == \"Mahikeng Water TreatmentWorks\")\n</code></pre> <p>We then generate an epiweeks column for the wastewater samples based on the sample collection dates. We also set up the columns we need by simplifying the column names, and creating a column with the log genome copies per ml </p> <pre><code>water1 &lt;- water\nwater1 &lt;- water1 %&gt;% arrange(ymd(water1$sam_col_date))\nwater1$epiweek &lt;- lubridate::epiweek(ymd(water1$sam_col_date)) #generate epiweek\nwater1$year &lt;- strftime(water1$sam_col_date, \"%Y\") #Creating year column  \nwater1$week &lt;- \"w\" #added column with w\nmy_cols &lt;- c(\"year\", \"week\", \"epiweek\") #new data object with 3 columns combined\nwater1$epiweek2 &lt;- do.call(paste, c(water1[my_cols],sep =\"\")) #created new variable using concat columns\n\nwater1$levels &lt;- water1$n_gene_ml\nwater1$Date &lt;- water1$sam_col_date\nwater1$Result &lt;-water1$sars_cov_2_pcr_result\nwater1 &lt;- water1 %&gt;%\n  mutate(levels = na_if(levels, levels &lt; 0))\nwater1 &lt;- water1 %&gt;%\n  mutate(levels = if_else(levels&lt;2.34, 2.34, levels)) #replace lower than 2.34 with 2.34 (limit of quantification for qPCR)\nwater1$loglevels &lt;- log10(water1$levels)\n</code></pre> <p>Since wastewater levels were initially tested using a qPCR and later change to dPCR, we add a quality check for the \"PCR\" column which ensure the correct  type of PCR is indicated based on when we switched to dPCR (epiweek 30 of 2023) </p> <pre><code>water1 &lt;- water1 %&gt;%\n  mutate(PCR = if_else(year == 2021, \"qPCR\", PCR)) %&gt;%\n  mutate(PCR = if_else(year == 2022, \"qPCR\", PCR)) %&gt;%\n  mutate(PCR = if_else(year == 2023 &amp; week &lt; 30, \"qPCR\", PCR)) %&gt;%\n  mutate(PCR = if_else(year == 2023 &amp; week &gt; 30, \"dPCR\", PCR)) %&gt;%\n  mutate(PCR = if_else(year == 2024, \"dPCR\", PCR))\n</code></pre>"},{"location":"quantitative/#plotting-clinical-cases-against-wastewater-levels","title":"Plotting clinical cases against wastewater levels","text":"<p>We'll start by plotting the national waterwater levels against the clinical cases. The wasterwater levels will be in the form of a line graph,  and bars will be used to represent the number of clinical cases.  </p> <p>We start by tabulating the number of samples received </p> <pre><code>rsa_samples &lt;- cases1 %&gt;%\n  group_by(epiweek2)%&gt;%\ncount(epiweek2, na.rm=TRUE)\n\nrsa_water &lt;- water1 %&gt;% \n  filter( Site.Name. == \"Goudkoppies Wastewater Treatment Works\" |\n        Site.Name. == \"Northern Wastewater Treatment Works\"| \n        Site.Name. == \"Rooiwal Wastewater Treatment Works\" |\n        Site.Name. == \"Daspoort Wastewater Treatment Works\" |\n        Site.Name. == \"ERWAT Vlakplaat Wastewater Treatment Works\" |\n        Site.Name. == \"Hartebeesfontein Waterworks\" |\n        Site.Name. == \"Zandvleit Wastewater Treatment Works\" |\n        Site.Name. == \"Borcheds Quarry Wastewater Treatment Works\" |\n        Site.Name. == \"East Bank Wastewater Treatment Works \" |\n        Site.Name. == \"Mdantsane Wastewater Treatment Works\"|\n        Site.Name. == \"Brickfield Pre-treatment Works  \" |\n        Site.Name. == \"Kwanobuhle Wastewater Treatment Works\"|\n        Site.Name. == \"Sterkwater Wastewater Treatment Works \" |\n        Site.Name. == \"Bloemspruit Wastewater Treatment Works\"| \n        Site.Name. == \"Central Wastewater Treatment Works \" |\n        Site.Name. == \"Northern Wastewater Treatment Works\"|\n        Site.Name. == \"Mahikeng Water Treatment Works\"|\n        Site.Name. == \"Mmabatho Water Treatment Work\"|\n        Site.Name. == \"Rustenburg Wastewater Treatment Works\")\n\nrsacopies &lt;- rsa_water %&gt;% \n  group_by(epiweek2)%&gt;%\n  summarise(sum_genomes = sum(levels,na.rm = TRUE),\n        .groups = 'keep')\n\nrsacopies[\"sum_genomes\"][rsacopies[\"sum_genomes\"] == 0] &lt;- NA\n\nrsacases_vs_water&lt;- full_join(rsa_samples, rsa_water, by= \"epiweek2\")\nrsacases_vs_water&lt;- full_join(rsacases_vs_water, rsacopies, by= \"epiweek2\")\n</code></pre> <p>We then repeat this for weeks where there are clinical cases but no wastewater samples otherwise it would be blank</p> <pre><code>rsacases_vs_water &lt;- rsacases_vs_water %&gt;%\n  mutate(PCR = if_else(year == 2021, \"qPCR\", PCR)) %&gt;%\n  mutate(PCR = if_else(year == 2022, \"qPCR\", PCR)) %&gt;%\n  mutate(PCR = if_else(year == 2023 &amp; week &lt; 30, \"qPCR\", PCR)) %&gt;%\n  mutate(PCR = if_else(year == 2023 &amp; week &gt; 30, \"dPCR\", PCR)) %&gt;%\n  mutate(PCR = if_else(year == 2024, \"dPCR\", PCR)) %&gt;%\n  mutate(PCR = if_else(is.na(PCR), \"qPCR\", PCR))\n\n\nrsacases_vs_water$final_result &lt;- rsacases_vs_water$SARS.CoV.2.PCR.result\n</code></pre> <p>Since we don't need all the columns currently in the dataframe, select the columns we want, which is a bit easier to work with.     rsacases_vs_water &lt;- rsacases_vs_water %&gt;%       select(epiweek2, n, sum_genomes, Date, PCR)</p> <p>We calculate log10 of sum_genomes and store it in a new column loglevels</p> <pre><code>rsacases_vs_water$loglevels &lt;- log10(rsacases_vs_water$sum_genomes)\n</code></pre> <p>In our reports we use square markers to indicate weeks where samples were tested. We place these markers below zero on the x-axis, in line with the corresponding epiweek. In order to do this we create a new column (tested).  We use the mutate function to create these columns and assign the value -0.3 if a sample was tested.  The values -0.3 is arbitrary, and was selected to ensure the marker is graphed below zero.</p> <pre><code>rsacases_vs_water&lt;- rsacases_vs_water %&gt;%\n  mutate(tested = case_when( (sum_genomes &gt; 0) ~ -0.3)) %&gt;%\n  mutate(n = if_else(is.na(n), 0, n)) #replace na with 0\n</code></pre> <p>Before plotting, we want to ensure that the correct order of the epiweeks such that the order is by year first, then week. To do this we first create a copy of epiweek2 and name it epiweek3</p> <pre><code>rsacases_vs_water$epiweek3 &lt;- rsacases_vs_water$epiweek2\n</code></pre> <p>Then we split the epiweek3 column into a \"year\" column and a \"week\" column. We then convert the values in these columns into integers.</p> <pre><code>rsacases_vs_water &lt;- rsacases_vs_water %&gt;%\n  separate(epiweek3, sep = \"w\", into = c(\"year\", \"week\")) %&gt;%\n  mutate(across(c(\"year\", \"week\"), as.integer))\n</code></pre> <p>Since we only started testing wastewater samples for SARS-CoV-2 in 2021, we filter out and clinical samples from 2020</p> <pre><code>rsacases_vs_water &lt;- rsacases_vs_water %&gt;%\n  filter(year != 2020)\n</code></pre> <p>Now we can order the samples first by year and then week</p> <pre><code>rsacases_vs_water &lt;-  rsacases_vs_water[ #ordering by year first then week\n  with(rsacases_vs_water, order(year, week)),\n]\n</code></pre> <p>To ensure this order stays the same when we're plotting the graph, we conver epiweek2 into an ordered factor.</p> <pre><code>rsacases_vs_water$epiweek2 &lt;- factor(rsacases_vs_water$epiweek2, levels = unique(rsacases_vs_water$epiweek2), ordered = T)\n</code></pre> <p>Add a new column \"Country\" with a constant value.</p> <pre><code>rsacases_vs_water$Country &lt;- \"South African SARS-CoV-2 Wastewater Levels\"\n\nrsacases_vs_water$Date &lt;- \"w\"\n</code></pre> <p>Remove duplicated rows </p> <pre><code>rsacases_vs_water &lt;- rsacases_vs_water %&gt;% distinct()\n</code></pre> <p>Create a new column 'end' by parsing date and time using the lubridate package. Then we concatenate year, week, and 0 with \"-\" as separator to form a string. Specify the format 'Y-W-w' where 'Y' is year, 'W' is week, and 'w' is the day of the week (0 = week start on Sunday).Add 6 days to the parsed date to get the end of the epidemiological week. This function parses the concatenated string into a date-time object.The resulting date represents the start of the epidemiological week, so adding 6 days gives the end of the week. This is mainly used for getting the last day of the epidemilogical week which is used on the dashboard. </p> <pre><code>rsacases_vs_water$end &lt;- lubridate::parse_date_time(paste(rsacases_vs_water$year, rsacases_vs_water$week,0, sep=\"-\"),'Y-W-w') + days(6)\n#lubridate::parse_date_time(year, week, 0= week start on sunday, sep = formwat you want)\n#this gives start of epiweek so add 6 days to get end of epiweek\n</code></pre> <p>This next line of code is only necessary if you have many samples spanning multiple years. You may want to only show every nth epiweek on the graph instead of every week as this may appear cluttered.  This funtion allows you to return every nth element. When added to the graph, you specify the value of n.</p> <pre><code>every_nth = function(n) {\n  return(function(x) {x[c(TRUE, rep(FALSE, n - 1))]})\n}\n</code></pre> <p>We then plot the graph.This line opens a PNG device to create a file named overall_rsa.png. The dimensions are set to 5 times 950 pixels in width and 5 times 300 pixels in height. The resolution is set to 300 DPI. The point size for text and points in the plot is set to 8. </p> <pre><code>png(\"/path/to/file/overall_rsa.png\",  # Create a PNG file for the plot\n    width = 5 * 950,  # Set width of the image\n    height = 5 * 300,  # Set height of the image\n    res = 300,  # Set resolution of the image\n    pointsize = 8)  # Set point size for the image\n</code></pre> <p>This initializes a ggplot object using the rsacases_vs_water data frame.</p> <pre><code>rsaplot &lt;- ggplot(rsacases_vs_water) +  # Create a ggplot object with rsacases_vs_water data frame\n</code></pre> <p>This adds points to the plot representing the tested samples multiplied by 10000. Points are grouped by 1 and colored according to \"Sample Collection\". The size of the points is set to 1, and the shape is set to 15.</p> <pre><code>geom_point(aes(x = epiweek2, y = tested * 10000, group = 1, col = \"Sample Collection\"), stat = \"identity\", size = 1, shape = 15) +  # Add points for sample collection\n</code></pre> <p>This adds a bar plot for the number of samples (n) for each epidemiological week (epiweek2). Bars are filled and colored gray.</p> <pre><code>geom_bar(aes(x = epiweek2, y = n), stat = \"identity\", fill = \"gray\", colour = \"gray\") +  # Add bar plot for number of cases\n</code></pre> <p>This adds points for log genome copies multiplied by 10000. Points are grouped and colored by the Country variable. The size of the points is set to 2.</p> <pre><code>geom_point(aes(x = epiweek2, y = loglevels * 10000, group = Country, col = Country), stat = \"identity\", size = 2) +  # Add points for log genome copies\n</code></pre> <p>This adds lines for log genome copies multiplied by 10000. Lines are grouped and colored by the Country variable. The size of the lines is set to 1.</p> <pre><code>geom_line(aes(x = epiweek2, y = loglevels * 10000, group = Country, col = Country), stat = \"identity\", size = 1) +  # Add lines for log genome copies\n</code></pre> <p>This sets the x-axis breaks to show every 2nd label</p> <pre><code>scale_x_discrete(breaks = every_nth(n = 2)) +  # Set x-axis breaks to show every 2nd label\n</code></pre> <p>This manually sets the colors for the points and lines. \"Sample Collection\" is colored dark blue. \"South African SARS-CoV-2 Wastewater Levels\" is colored #009ADE (a shade of blue).</p> <pre><code>scale_colour_manual(values = c(\"Sample Collection\" = \"darkblue\", \"South African SARS-CoV-2 Wastewater Levels\" = \"#009ADE\")) +  # Set custom colors for the points and lines\n</code></pre> <p>This customizes the legend, overriding the aesthetics for shape and line type.</p> <pre><code>guides(color = guide_legend(override.aes = list(shape = c(15, 16), linetype = c(0, 1)))) +  # Customize legend\n</code></pre> <p>This sets the y-axis to have a secondary axis for log genome copies divided by 10000. The secondary axis is labeled \"Log Genome Copies/ml (N Gene)\". The y-axis has 4 breaks, and labels are formatted with comma</p> <pre><code>scale_y_continuous(sec.axis = sec_axis(~ . / 10000, name = \"Log Genome Copies/ml (N Gene)\\n\"),  # Create secondary y-axis for log genome copies\n                 breaks = scales::pretty_breaks(n = 4),  # Set breaks for the y-axis\n                 labels = scales::label_comma()) +  # Format y-axis labels with commas\n</code></pre> <p>This adds labels to the x-axis (\"Epidemiological week\") and y-axis (\"Laboratory confirmed cases\").</p> <pre><code>labs(x = \"\\nEpidemiological week\", y = \"Laboratory confirmed cases\\n\") +  # Add axis labels\n</code></pre> <p>This creates facets for the PCR variable, with levels \"qPCR\" and \"dPCR\". The x-axis scales are free within each facet, and the spacing is free.</p> <pre><code>facet_grid(~factor(PCR, levels = c('qPCR', 'dPCR')), scales = \"free_x\", space = \"free_x\") +  # Create facets for PCR method with free scales\n</code></pre> <p>This customizes various theme elements: x-axis text is rotated 90 degrees, aligned horizontally at 0, colored black, and sized 12. y-axis text is colored black and sized 12. The legend is positioned at the bottom, and its title is removed. General text is colored black and sized 12. x-axis and y-axis lines are colored black and sized 1. Facet background is white, and facet text is sized 12</p> <pre><code>ggthemes::theme_tufte() +  # Apply Tufte theme\ntheme(\n    axis.text.x = element_text(angle = 90, hjust = 0, color = \"black\", size = 12),  # Customize x-axis text\n    axis.text.y = element_text(color = \"black\", size = 12),  # Customize y-axis text\n    legend.position = \"bottom\",  # Place legend at the bottom\n    legend.title = element_blank(),  # Remove legend title\n    text = element_text(color = \"black\", size = 12),  # Set general text properties\n    axis.line.x = element_line(color = \"black\", size = 1),  # Customize x-axis line\n    axis.line.y = element_line(color = \"black\", size = 1),  # Customize y-axis line\n    strip.background = element_rect(fill = \"white\"),  # Customize facet background\n    strip.text = element_text(size = 12)  # Customize facet text\n)\n</code></pre> <p>This line displays the ggplot object created.</p> <pre><code>rsaplot  # Plot the ggplot object\n</code></pre> <p>This closes the PNG device, saving the plot to the file.</p> <pre><code>dev.off()  # Close the PNG device\n</code></pre> <p></p>"},{"location":"quantitative/#creating-a-district-level-plot","title":"Creating a district level plot","text":"<p>Below is the continuation and completion of the detailed guide for performing SARS-CoV-2 quantitative levels analysis using R.  This guide includes plotting the data at a district level. In the example below we have selected Johannesburg as our district of interest. For other districts, replace the District Name and Site Names for  your district of interest. </p> <p>First start by tabulating the number of samples received. We do this by grouping the samples by epidemiological week and then counting the number of samples per week. </p> <pre><code>jhb_samples &lt;- joburg_cases %&gt;%\n  group_by(epiweek2)%&gt;%\n  count(epiweek2, na.rm=TRUE)\n</code></pre> <p>Then we filter for samples that were collected in our district of interest and at the wastewater treatment plants of interest. In this case we're filtering for samples  collected in the Johannesburg Municipality, at the Goudkoppies and Northern Wastewater Treatment Plants.  </p> <pre><code>jhb_water &lt;- water1 %&gt;% \n  filter(District.Name == \"Johannesburg MM\") %&gt;%\n  filter( Site.Name. == \"Goudkoppies Wastewater Treatment Works\" |\n        Site.Name. == \"Northern Wastewater Treatment Works (GP)\")\n</code></pre> <p>We then merge the two data frames and create a new column for the final PCR results. </p> <pre><code>jhbcases_vs_water&lt;- full_join(jhb_samples, jhb_water, by= \"epiweek2\")\njhbcases_vs_water$final_result &lt;- jhbcases_vs_water$SARS.CoV.2.PCR.result\n</code></pre> <p>We then select relevant columns we would like to work with, and remove rows that have invalid epiweek values i.e all samples in which epiweek2 = NAwNA as these are  samples which had no sample collection dates.</p> <pre><code>jhbcases_vs_water &lt;- jhbcases_vs_water %&gt;% \n  select(epiweek2, n, Site.Name., \n     Site.Province., District.Name,Genome.copies.mL...N.gene.., levels, loglevels, Date, final_result, PCR) %&gt;% \n  filter(epiweek2 != \"NAwNA\")\n</code></pre> <p>In our reports we use square markers to indicate weeks where samples were tested. We place these markers below zero on the x-axis, in line with the corresponding epiweek. In order to do this we create new columns (tested1 and tested2) for each WWTP. We use the mutate function to create these columns and assign the value -0.3 or -0.1 for each site if a sample was tested and had a Positive or Negative result. The values -0.3 and -0.1 are arbitrary, and were selected to ensure the marker is graphed below zero.  </p> <pre><code>jhbcases_vs_water&lt;- jhbcases_vs_water %&gt;%\n  mutate(tested1 = case_when( (Site.Name. == \"Goudkoppies Wastewater Treatment Works\" &amp; final_result == \"Positive\") ~ -0.3, \n                          (Site.Name. == \"Goudkoppies Wastewater Treatment Works\" &amp; final_result == \"Negative\") ~ -0.3)) %&gt;%\n  mutate(tested2 = case_when( (Site.Name. == \"Northern Wastewater Treatment Works (GP)\" &amp; final_result == \"Positive\") ~ -0.1, \n                          (Site.Name. == \"Northern Wastewater Treatment Works (GP)\" &amp; final_result == \"Negative\") ~ -0.1))\n</code></pre> <p>Before plotting, we want to ensure that the correct order of the epiweeks such that the order is by year first, then week.  To do this we first create a copy of epiweek2 and name it epiweek3 </p> <pre><code>jhbcases_vs_water$epiweek3 &lt;- jhbcases_vs_water$epiweek2\n</code></pre> <p>Then we split the epiweek3 column into a \"year\" column and a \"week\" column. We then convert the values in these columns into integers. </p> <pre><code>jhbcases_vs_water &lt;- jhbcases_vs_water %&gt;%\n  separate(epiweek3, sep = \"w\", into = c(\"year\", \"week\")) %&gt;%\n  mutate(across(c(\"year\", \"week\"), as.integer))\n</code></pre> <p>Since we only started testing wastewater samples for SARS-CoV-2 in 2021, we filter out and clinical samples from 2020</p> <pre><code>jhbcases_vs_water &lt;- jhbcases_vs_water %&gt;%\n  filter(year != 2020)\n</code></pre> <p>Now we can order the samples first by year and then week</p> <pre><code>jhbcases_vs_water &lt;-  jhbcases_vs_water[ #ordering by year first then week\n  with(jhbcases_vs_water, order(year, week)),\n]\n</code></pre> <p>To ensure this order stays the same when we're plotting the graph, we conver epiweek2 into an ordered factor.</p> <pre><code>jhbcases_vs_water$epiweek2 &lt;- factor(jhbcases_vs_water$epiweek2, levels = unique(jhbcases_vs_water$epiweek2), ordered = T)\n</code></pre> <p>Initially samples were tested using a qPCR but during 2023, we switched to testing samples using a dPCR. This change is indicated in our graphs using facets which show the type of PCR test performed. To create these facets, we first specify which type of PCR test was performed based on when the samples were collected. </p> <pre><code>jhbcases_vs_water &lt;- jhbcases_vs_water %&gt;%\n  mutate(PCR = if_else(year == 2021, \"qPCR\", PCR)) %&gt;% # Set PCR method for 2021 to qPCR\n  mutate(PCR = if_else(year == 2022, \"qPCR\", PCR)) %&gt;% # Set PCR method for 2022 to qPCR\n  mutate(PCR = if_else(year == 2023 &amp; week &lt; 30, \"qPCR\", PCR)) %&gt;% # Set PCR method for early 2023 to qPCR\n  mutate(PCR = if_else(year == 2023 &amp; week &gt; 30, \"dPCR\", PCR)) %&gt;% # Set PCR method for late 2023 to dPCR\n  mutate(PCR = if_else(is.na(PCR), \"qPCR\", PCR)) %&gt;% # Replace NA PCR values with qPCR\n  mutate(n = if_else(is.na(n), 0, n)) #replace na with 0\n</code></pre> <p>This next line of code is only necessary if you have many samples spanning multiple years. You may want to only show every nth epiweek on the graph instead of every week as this may appear cluttered.  This funtion allows you to return every nth element. When added to the graph, you specify the value of n.</p> <pre><code>every_nth = function(n) {\n  return(function(x) {x[c(TRUE, rep(FALSE, n - 1))]})\n}\n</code></pre> <p>Then we create the graph and save it as a png file.</p> <pre><code>png(\"/path/yo/file/Johannesburg.png\", # Create a PNG file for the plot \n    width = 5*950,  # Set width of the image\n    height = 5*300, # Set height of the image\n    res = 300, # Set resolution of the image\n    pointsize = 8) # Set point size for the image\n\njhbplot &lt;- ggplot(jhbcases_vs_water) +    # Create ggplot object with jhbcases_vs_water data frame\ngeom_bar(aes(x = epiweek2, y = n), stat = \"identity\", fill = \"gray\", colour = \"gray\") +   # Add bar plot for number of cases\ngeom_point(aes(x = epiweek2, y = tested1 * 10000, group = 1, col = \"Goudkoppies Sample Collection\"), stat = \"identity\", size = 1, shape = 15) +   # Add points for Goudkoppies sample collection\ngeom_point(aes(x = epiweek2, y = tested2 * 10000, group = 1, col = \"Northern Sample Collection\"), stat = \"identity\", size = 1, shape = 15) +   # Add points for Northern sample collection\ngeom_point(aes(x = epiweek2, y = loglevels * 10000, group = Site.Name., col = Site.Name.), stat = \"identity\", size = 2) +   # Add points for log genome copies\ngeom_line(aes(x = epiweek2, y = loglevels * 10000, group = Site.Name., col = Site.Name.), stat = \"identity\", size = 1) +   # Add lines for log genome copies\nscale_colour_manual(values = c(\"Goudkoppies Sample Collection\" = \"darkred\", \"Northern Sample Collection\" = \"darkblue\", \n                            \"Goudkoppies Wastewater Treatment Works\" = \"#FC4E2A\", \"Northern Wastewater Treatment Works (GP)\" = \"#009ADE\")) +   # Set custom colors for the points and lines\nscale_y_continuous(sec.axis = sec_axis(~ . / 10000, name = \"Log Genome Copies/ml (N Gene)\\n\"),   # Create secondary y-axis for log genome copies\n                 breaks = scales::pretty_breaks(n = 2),   # Set breaks for the y-axis\n                 labels = scales::label_comma()) +   # Format y-axis labels with commas\nguides(color = guide_legend(override.aes = list(shape = c(15, 16, 15, 16),   # Customize legend\n                                              linetype = c(0, 1, 0, 1)))) +   \nscale_x_discrete(breaks = every_nth(n = 5)) +   # Set x-axis breaks to show every 5th label\nfacet_grid(~factor(PCR, levels = c('qPCR', 'dPCR')), scales = \"free_x\", space = \"free\") +   # Create facets for PCR method with free scales\nlabs(x = \"\\nEpidemiological week\", y = \"Laboratory confirmed cases\\n\") +   # Add axis labels\nggthemes::theme_tufte() +   # Apply Tufte theme\ntheme(\n    axis.text.x = element_text(angle = 90, hjust = 0, color = \"black\", size = 16),   # Customize x-axis text\n    axis.text.y = element_text(color = \"black\", size = 16),   # Customize y-axis text\n    legend.position = \"bottom\",   # Place legend at the bottom\n    legend.title = element_blank(),   # Remove legend title\n    text = element_text(color = \"black\", size = 16),   # Set general text properties\n    axis.line.x = element_line(color = \"black\", size = 1),   # Customize x-axis line\n    axis.line.y = element_line(color = \"black\", size = 1),   # Customize y-axis line\n    strip.background = element_rect(fill = \"white\"),   # Customize facet background\n    strip.text = element_text(size = 12))   # Customize facet text\n\njhbplot   # Plot the ggplot object\n\ndev.off()   # Close the PNG device\n</code></pre> <p></p>"},{"location":"sample_maps/","title":"GIS graphs for Sample Tracking","text":"<p>When wastewater samples are collected, the RedCap Mobile App is used to capture  the sample collection forms. These forms contain information about when, where and  how a sample was collected.This helps us ensure that samples are collected from  the correct sites and assists in sample tracking. </p> <p>Since we have the location (longitude and latitute) of the samples being collected,  we can plot them on a map using R and Google Maps. Other GIS software, such as ArcGIS,  may also be used; however, for this tuturial we will only be using open source software. </p>"},{"location":"sample_maps/#setting-up","title":"Setting up","text":"<p>In order to run this script you will need R version 4.2.2 or higher. You will also need to register a Google API in order to be able to make use of Google services within R.  To register with google you can visit the Google Maps Platform</p> <p>Once registered, ensure that you enable your API. It is important to note that your API key should be kept private  and should not be shared with anyone else. This key will be used to connect with Google Maps using your R script. </p> <p>To get started, you will need the following packages to run the script: ggmap, rstudioapi, tidyverse, lubridate and ggrepel. </p> <p>If you do not already have these packages installed, you can simply use the install.packages() function. You can simply copy and paste the below and click \"Run\" to install the package: </p> <pre><code>install.packages(\"ggmap\")\n</code></pre> <p>Multiple packages can also be installed at the same time by creating a list of the packages to be installed using the c() function: </p> <pre><code>install.packages(c(\"ggmap\", \"rstudioapi\", \"tidyverse\", \"lubridate\", \"ggrepel\"))\n</code></pre> <p>Once you have installed a package in R, you don't need to install it again when you subsequently use R.  However, you do need to tell R which packages you would like to use to run the script.  We can do this using the library() function: </p> <pre><code>library(ggmap)\nlibrary(rstudioapi)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(ggrepel)\n</code></pre> <p>Once we have loaded the libraries we would like to use, we have to connect to Google using our API key. We can do this using: </p> <pre><code>register_google(key = 'enter-your-key-here')\n</code></pre>"},{"location":"sample_maps/#preparing-our-data","title":"Preparing our data","text":"<p>Now we are ready to work with our data. As previously mentioned, this data is collected using RedCap. In order to obtain this data  you will need to export it from RedCap. The data exported is in the form of a .csv file.</p> <p>You can download an example dataset to practice with here: wastewater_sample_data.csv</p> <p>We can take that csv file and save it as a dataframe which we will call \"map\" using the read.csv() function: </p> <pre><code>map &lt;- read.csv(\"Path/to/the/file.csv\", check.names = F) #Replace the path with the path to the file on your computer\n</code></pre> <p>If you view the \"map\" dataframe, you will notice that each column name is separated by a fullstop. This is because spaces in  column headings were replace with a fullstop when we were reading in the csv file. For example: \"Sample Number\"  becomes \"Sample.Number.\". To make it a bit easier to work with, we are going to rename the columns we will be working with:</p> <pre><code>map$record_id &lt;- map$Sample.Number.\nmap$sam_site_id &lt;- map$Sample.Site.Identification.Number.\nmap$site_latitude &lt;- map$Site.Location..lat.\nmap$site_longitude &lt;- map$Site.Location..long.\nmap$sam_col_date &lt;- as.Date(map$Sample.Collection.Date) #the as.Date() function just ensures that the dates are being recognised as dates\nmap$sam_col_tim &lt;- map$Sample.Collection.Time.\n</code></pre> <p>Since we only want to work with these columns, we're going to filter out all the ones we don't need and select the ones we want to work with. This step isn't really that necessary, but helps keeps things tidy and is easier to work with: </p> <pre><code>map &lt;- map %&gt;% \n       select(record_id, sam_site_id, site_latitude, site_longitude, sam_col_date, sam_col_tim)\n</code></pre> <p>Since we report our findings using epidemiological weeks, or epiweeks, we want to add another column with the epiweeks.  We can use the sample collection date to calculate the epiweek: </p> <pre><code>map$epiweek &lt;- lubridate::epiweek(ymd(map$sam_col_date)) #ymd indicates that our dates are saved in the year-month-day format (e.g. 2023-09-15)\n</code></pre> <p>We also want to create a column which has both the year and epiweek (e.g. 2023w36). In order to produce this we first  have to create a column with the year, another column with the week and then finally concatenate the columns to create the new epiweek2 variable:</p> <pre><code>map$year &lt;- strftime(map$sam_col_date, \"%Y\") #Creating year column  \nmap$week &lt;- \"w\" #creating a week column with \"w\" representing the weeks. \nmy_cols &lt;- c(\"year\", \"week\", \"epiweek\") #creating a new data object which combines the 3 columns in the specified order\nmap$epiweek2 &lt;- do.call(paste, c(map[my_cols],sep =\"\")) #taking that data object and saving it in the newly created epiweek2 column\n</code></pre> <p>The \"map\" dataframe should now look like the example below. </p> <p> </p>"},{"location":"sample_maps/#generating-the-maps","title":"Generating the maps","text":"<p>Now that our data is in the format that we want, we can create maps of where the samples were created. The first map will show all points at which samples were collected.</p> <p>We first have to specify that we want to save the map as an image as well as the folder we would like the map to be stored</p> <pre><code>png(\"path/to/file/map1.png\", \n    width = 5*900, #specify width dimension\n    height = 5*500, #specify height dimension\n    res = 300, #specifying the resolution of the image\n    pointsize = 8)\n</code></pre> <p>Then we generate the site map. Because google map uses the location at the center of a map, we must first supply it with the coordinates at the center of our sample collection sites.  For our sample collection sites we use the following coordinates as the center of our map. </p> <p>City of Ekurhuleni: lon = 28.23570, lat = -25.99873</p> <p>City of Johannesburg:lon = lon = 27.91593 , lat = -26.31008</p> <p>City of Tshwane:lon = 28.12 , lat = -25.76257</p> <p>If you want to generate a map for a different city, you can simple use that city's coordinates as the center of your map.</p> <p>To generate a map of all samples collected in the City of Ekurhuleni we first have to tell Google when the center of our map is</p> <pre><code>coe_sites &lt;- ggmap(get_googlemap(center = c(lon = 27.91593 , lat = -26.31008),\n                             zoom = 12,\n                             maptype = \"hybrid\",\n                             color = \"color\")) +\n</code></pre> <p>To add points (red dots) where samples were collected onto the Google Maps, we use the coordinates  of each sample collected in the \"map\" dataframe we created. </p> <pre><code>geom_point(data = map, aes(x= site_longitude, y=site_latitude),\n         color = \"red\", #we specify the colour of our points\n         size= 2) + #we specify the size of our point\ntheme(axis.title = element_blank(), #This remove the title from the map\n    axis.text = element_blank(), #This removes coordinates from being displayed along the x- and y-axis\n    axis.ticks = element_blank()) #This removes any axis-ticks\n</code></pre> <p>To then generate the maps, we finally run: </p> <pre><code>coj_sites\ndev.off()\n</code></pre> <p>You should now have a map illustrating all sample collection points in the City of Ekurhuleni.</p> <p></p> <p>In order to generate a map showing samples collected during a specific  epiweek, as well as the time in which those samples were collected, we will  first create another dataframe called \"map2\" and filter for a specific epiweek: </p> <pre><code>map2 &lt;- map%&gt;% \nfilter(epiweek == 37)\n</code></pre> <p>Then we create a map of all the points collected during that epiweek: </p> <pre><code>png(\"path/to/file/map2.png\", \n    width = 5*900,\n    height = 5*500, \n    res = 300,\n    pointsize = 8)\n\ncoe_sites2 &lt;- ggmap(get_googlemap(center = c(lon = 28.23570, lat = -25.99873),\n                             zoom =12,\n                             scale = 2,\n                             maptype = \"hybrid\",\n                             color = \"color\")) +\ngeom_point(data = map2, aes(x= site_longitude, y=site_latitude), #ensure that you are using the filtered \"map2\" dataframe\n         color = \"red\", \n         size= 2) +\n</code></pre> <p>In addition to creating the map we want to add labels showing the sample collection times. Since the sample colletion times are also recorded on  the sample collection forms, we can use the geom_label_repel() function to convert those times into sample labels. Here we specify that for each sample, the longitude will be use as our x-coordinate, latitute for the y-coordinate and sample collection time as the label</p> <pre><code>geom_label_repel(data = map2, \n               aes(x= site_longitude, y=site_latitude, label = sam_col_tim), \n               size = 6)+ #specify size of the label\ntheme(axis.title = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank())\ncoe_sites2\ndev.off()\n</code></pre> <p>You should now have two maps illustrating the sample collection points. </p> <p></p>"},{"location":"sequencing/","title":"Wastewater Genomics Sequencing Analysis For SARS-CoV-2","text":""},{"location":"sequencing/#purpose","title":"Purpose","text":"<p>This documentation page outlines the procedure for processing and analyzing wastewater sequencing data as part of the wastewater genomics surveillance program. The goal is to ensure consistent, accurate, and reliable data for public health monitoring and decision-making.</p>"},{"location":"sequencing/#definitions","title":"Definitions","text":"<ul> <li>BWA: BWA is a software package used to map sequences with low divergence to a sizable reference genome, like the Wuhan-hu SARS-CoV-2 genome. Three algorithms make up this system: BWA-backtrack, BWA-SW, and BWA-MEM.</li> <li>Exatype: Exatype is a software platform developed by Hyrax Biosciences designed to analyze genetic sequences of viruses and other pathogens. Exatype could help in determining how these viruses are mutating and potentially inform the development of treatment strategies and vaccines by identifying mutations that might confer resistance to existing therapies.</li> <li>Freyja: Freyja is a tool to recover relative lineage abundances from mixed SARS-CoV-2 samples from a sequencing dataset (BAM aligned to the Hu-1 reference). The technique solves the limited (unit sum, non-negative) de-mixing problem by using lineage-determining mutational \u201cbarcodes\u201d produced from the UShER global phylogenetic tree as a basis set.</li> <li>Mutational profile: Refers to the characterization of mutations present within a genome, gene, or set of genes in an organism. This profile includes the types, locations, and frequencies of genetic alterations, providing insights into the molecular underpinnings of various conditions, diseases, or evolutionary processes.</li> <li>NGS: Next-generation Sequencing, a method used for precise and comprehensive analysis of the genetic material found in wastewater samples.</li> <li>Samtools: Samtools is a set of tools used to interact with high-throughput sequencing data.</li> <li>iVar: iVar is a software package that consists of functions broadly useful for viral amplicon-based sequencing.</li> <li>Wastewater sample: A sample collected from various wastewater catchment sites, intended for genomic analysis.</li> </ul> <p>All commands/scripts must be executed on a Linux server/environment with Conda activated.</p>"},{"location":"sequencing/#data-preprocessing","title":"Data Preprocessing","text":"<p>Raw sequence data preprocessing steps including quality control, trimming of adapters, and removal of low-quality sequences are performed by the NICD Sequencing Core Facility and are therefore not included in this documentation page.</p>"},{"location":"sequencing/#alignment","title":"Alignment","text":"<ul> <li>Aligning reads to reference SARS-CoV-2 genome:</li> </ul> <p>This script performs alignment of raw sequencing reads to the reference SARS-CoV-2 genome using the BWA (Burrows-Wheeler Aligner) tool. Before running, the input and output directories of all files are first defined. </p> <p>This line defines the path to the reference genome sequence file. The reference genome is the known sequence of the SARS-CoV-2 genome to which the raw sequencing reads will be aligned.</p> <pre><code> # Directory where your indexed reference sequence is\nREF=\u201d/path/to/reference/sequence.fa\n</code></pre> <p>This line defines the directory where the raw sequencing files (in fastq.gz format) are located. These are the files containing the raw reads obtained from sequencing the wastewater samples.</p> <pre><code>RAW_DIR=\"/path/to/raw_files\"\n</code></pre> <p>This line defines the output directory where the aligned SAM files will be saved.  SAM files (Sequence Alignment/Map) store the alignment information of reads to a reference genome.</p> <pre><code>OUT_DIR=\"./mapped_epi6_8\"\n</code></pre> <p>This command creates the output directory defined in OUT_DIR if it does not already exist.  The -p flag ensures that the command does not throw an error if the directory already exists.</p> <pre><code>mkdir -p \"$OUT_DIR\"\n</code></pre> <p>A for loop is created to iterate over each R1 fastq.gz file in the raw files directory (RAW_DIR). R1 fastq.gz files contain the forward reads  obtained from sequencing.The filename of the R1 file is then modified to generate the corresponding R2 filename.  In Illumina paired-end sequencing, R1 and R2 files contain paired-end reads, where R1 contains the forward reads and R2 contains the reverse reads.  This assumes a consistent naming convention where R1 files end with \"_R1_001.fastq.gz\" and R2 files end with \"_R2_001.fastq.gz\".</p> <pre><code>for R1 in \"$RAW_DIR\"/*_R1_001.fastq.gz; do\n# Assuming the naming convention is consistent, modify the suffix to find the R2 files\n    R2=\"${R1/_R1_/_R2_}\"\n# Extract the sample name based on the R1 file\n    SAMPLE_NAME=$(basename \"$R1\" \"_R1_001.fastq.gz\")\n# Construct the output file name\n    SAM_FILE=\"${OUT_DIR}/${SAMPLE_NAME}.aligned.sam\"\n</code></pre> <p>This line prints a message indicating which sample is being mapped.</p> <pre><code>echo \"Mapping $SAMPLE_NAME...\"\n</code></pre> <p>his line executes the BWA MEM algorithm to align the paired-end reads ($R1 and $R2) to the reference genome ($REF).  The alignment results are then redirected (&gt;) to the output SAM file ($SAM_FILE).</p> <pre><code>bwa mem \"$REF\" \"$R1\" \"$R2\" &gt; \"$SAM_FILE\"\n</code></pre> <p>This marks the end of the loop.</p> <pre><code>done\n</code></pre> <p>This line prints a message indicating that the mapping process for all samples is complete.</p> <pre><code>echo \"Mapping complete.\"\n</code></pre>"},{"location":"sequencing/#converting-sam-files-to-bam-file-and-sorting-the-bam-files","title":"Converting SAM files to BAM file, and sorting the BAM files**:","text":"<pre><code> ```bash\n # Script available in the documentation\n ```\n</code></pre>"},{"location":"sequencing/#read-trimming-variant-calling-and-analysis","title":"Read Trimming, Variant Calling, and Analysis:","text":"<ul> <li>Trimming the reads and sorting:</li> </ul> <p>This script will loop through all indexed BAM files in the indexed directory and then extract the base filename without the .sorted.bam extension. Ultimately it will define the output trimmed BAM file path and output trimmed and sorted BAM file path</p> <pre><code> for INDEXED_FILE in \"$INDEXED_DIR\"/*.sorted.bam; do\n BASENAME=$(basename \"$INDEXED_FILE\" .sorted.bam)\n TRIMMED_FILE=\"$TRIMMED_DIR/${BASENAME}.trimmed.bam\"\n</code></pre> <p>This line will now trim the reads for each sample</p> <pre><code> echo \"Trimming reads for $INDEXED_FILE\"\n ivar trim -b nCoV-2019_v1.bed -i \"$INDEXED_FILE\" -p \"$TRIMMED_FILE\" -q 15 -m 100 -s 4 -      e -x 3\n</code></pre> <p>This line will sort the trimmed reads</p> <pre><code> echo \"Sorting trimmed reads for $TRIMMED_FILE\"\n samtools sort \"$TRIMMED_FILE\" -o \"$TRIMMED_SORTED_FILE\"\n done\n echo \"Read trimming and sorting complete.\"\n</code></pre>"},{"location":"sequencing/#freyja-analysis","title":"Freyja Analysis:","text":"<ul> <li>Running Freyja variants:</li> <li> <p>This script will specify the directory where the variants and depths files are located.</p> <p>VARIANTS_DIR=\"/RAW/Depths_TSV_all_copy_B/TSV_all/TSV\"   DEPTHS_DIR=\"/RAW/Depths_TSV_all_copy_B/Depths_all/Depths\"</p> </li> </ul> <p>This will create the output directory (if not yet created) where the results will be stored</p> <pre><code>  OUTPUT_DIR=\"/RAW/Depths_TSV_all_copy_B/output\"\n  mkdir -p \"${OUTPUT_DIR}\"\n</code></pre> <p>Loop into the variant files in the variants directory and then extract the base name for matching with the depth file. It will then construct the path to the matching depth file and subsequently specify the output file name, ending with .demix.tsv.</p> <pre><code>  for variants_file in ${VARIANTS_DIR}/*.tsv; do\n  base_name=$(basename \"${variants_file}\" .tsv)\n  depth_file=\"${DEPTHS_DIR}/${base_name}.depths\"\n  output_file=\"${OUTPUT_DIR}/${base_name}.demix.tsv\"\n</code></pre> <p>This script will check if the depth file exists(not compulsory) then run the Freyja variants step.</p> <pre><code>  if [ ! -f \"${depth_file}\" ]; then\n echo \"Depth file for ${base_name} does not exist. Skipping...\"\n continue\n fi\n #Run Freyja demix\n echo \"Processing: ${base_name}\"\n freyja demix \"${variants_file}\" \"${depth_file}\" --output \"${output_file}\"\n done\n echo \"All samples processed.\"\n</code></pre> <ul> <li>Freyja Demix:</li> </ul> <p>This script will iterate over each TSV file created on the previous step then it runs the Freyja demix step using the tsv file and depths file.</p> <pre><code>   For tsv_file in /RAW/Depths_TSV_all_copy_B/TSV_all/TSV/*.tsv; do\n   sample_name=$(basename \u201ctsv_file\u201d .tsv)\n   depths_file= \u201c/RAW/Depths_TSV_all_copy_B/Depths/${sample_name}.depths\u201d\n   output_file=\u201dRAW/Freyja_demix/${sample_name}.demix.tsv\n   echo \u201cRunning Freyja for $tsv_file\u201d\n   Freyja demix \u201c$tsv_file\u201d \u201c$depths_file\u201d \u2013output \u201coutput_file\u201d\n   done.\n</code></pre> <ul> <li> <p>Aggregating the Freyja Output Files:</p> <p>freyja aggregate /RAW/Freyja_demix/ --ext .tsv \u2013output                           /RAW/Freyja_demix/aggregate_file/agg_epi2_8.tsv</p> </li> </ul>"},{"location":"sequencing/#mutational-and-snps-analysis","title":"Mutational and SNPs Analysis:","text":"<ul> <li>Exatype Parameters:      <code>Data Structure: Paired-end      Sequencing Platform: Illumina      Assay: ARTIC V4</code></li> <li>Generate Heatmap and Mutational Profile:      <code>R      # Script available in the documentation</code></li> </ul>"},{"location":"sequencing/#references","title":"References","text":"<ul> <li>Castellano, Sara, et al. \u201ciVar, an Interpretation-Oriented Tool to Manage the Update and Revision of Variant Annotation and Classification.\u201d Genes 12, no. 3 (March 8, 2021): 384. DOI: 10.3390/genes12030384</li> <li>Dahui, Qin. \u201cNext-Generation Sequencing and Its Clinical Application.\u201d Cancer Biology &amp; Medicine 16, no. 1 (February 1, 2019): 4\u201310. DOI: 10.20892/j.issn.2095-3941.2018.0055</li> <li>Grubaugh, N.D., Gangavarapu, K., Quick, J. et al. An amplicon-based sequencing framework for accurately measuring intrahost virus diversity using PrimalSeq and iVar. Genome Biol 20, 8 (2019). https://doi.org/10.1186/s13059-018-1618-7</li> <li>Karthikeyan, Smruthi, et al. \u201cWastewater Sequencing Reveals Early Cryptic SARS-CoV-2 Variant Transmission.\u201d Nature 609, no. 7925 (September 1, 2022): 101\u20138. DOI: 10.1038/s41586-022-05049-6</li> <li>Li, Heng, and Richard Durbin. \u201cFast and Accurate Short Read Alignment with Burrows\u2013Wheeler Transform.\u201d Bioinformatics 25, no. 14 (July 15, 2009): 1754\u201360. DOI: 10.1093/bioinformatics/btp324</li> <li>Yousif, Mukhlid, et al. \u201cSARS-CoV-2 Genomic Surveillance in Wastewater as a Model for Monitoring Evolution of Endemic Viruses.\u201d Nature Communications 14, no. 1 (October 10, 2023): 6325. DOI: 10.1038/s41467-023-41369-5</li> </ul>"}]}